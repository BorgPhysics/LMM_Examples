{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397dec6e",
   "metadata": {},
   "source": [
    "## Question Answering Pipeline Tests using ML-CHAMP\n",
    "\n",
    "Now that we have an initial working QA pipeline, we can begin to fine-tune the various components using ML-CHAMP to test and document various changes and settings while documenting the code that was generated, FAISS indexes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1824fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "# If you haven't pip installed the software, you can load it into memory as shown below.\n",
    "#  - be sure to change ml_champ_home to match the location of your copy of ML-CHAMP.\n",
    "# Temporarily simulate that the ML CHAMP library has been pip installed.\n",
    "# This section can be removed after there is a stable python library build.\n",
    "# Set this to where you have downloaded ML CHAMP.\n",
    "# ml_champ_home = 'D:/JupyterPrograms/00-ML-CHAMP/ML-CHAMP'  \n",
    "# print('ml_champ_home:', ml_champ_home)\n",
    "# sys.path.append(ml_champ_home)\n",
    "\n",
    "from ml_champ import Project\n",
    "from ml_champ import Ensemble\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f5de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\n",
      "Importing modules...\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'get_ai_project', 'get_history_record', 'postprocessing_commands', 'preprocessing_commands', 'run_postprocessing', 'run_preprocessing', 'run_preprocessing_NO', 'test_model', 'train_model']\n"
     ]
    }
   ],
   "source": [
    "project_name = 'QA_Pipeline_Testing'\n",
    "project = Project(project_name)\n",
    "\n",
    "# print(dir(project))\n",
    "print(dir(project.model))\n",
    "\n",
    "# project = Project()\n",
    "# project.create_project(project_name=project_name)\n",
    "summary_model, summary_tokenizer = None, None\n",
    "question_answer_model, question_answer_tokenizer = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4421d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "\n",
    "    # from model_settings import get_summarization_model_and_tokenizer\n",
    "    if summary_model and summary_tokenizer:\n",
    "        if not model_settings.summarization_model and not model_settings.summarization_tokenizer:\n",
    "#             print('SETTING SUMMARIZER OBJECTS from Jupyter')\n",
    "            model_settings.set_summarization_model_and_tokenizer(summary_model, summary_tokenizer)\n",
    "#         else:\n",
    "#             print('Summarization model and tokenizer are set.')\n",
    "#             print(summary_model)\n",
    "#             print(summary_tokenizer)\n",
    "#             print(model_settings.summarization_model)\n",
    "#             print(model_settings.summarization_tokenizer)\n",
    "\n",
    "    # from model_settings import get_qa_model_and_tokenizer\n",
    "    if question_answer_model and question_answer_tokenizer:\n",
    "        if not model_settings.qa_model and not model_settings.qa_tokenizer:\n",
    "#             print('SETTING QA OBJECTS from Jupyter')\n",
    "            model_settings.set_qa_model_and_tokenizer(question_answer_model, question_answer_tokenizer)\n",
    "#         else:\n",
    "#             print('Question/answer model and tokenizer are set.')\n",
    "#             print(question_answer_model)\n",
    "#             print(question_answer_tokenizer)\n",
    "#             print(model_settings.qa_model)\n",
    "#             print(model_settings.qa_tokenizer)\n",
    "    \n",
    "def set_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "    \n",
    "    if not summary_model or not summary_tokenizer:\n",
    "#         print('GETTING SUMMARY OBJECTS')\n",
    "        summary_model, summary_tokenizer = model_settings.get_summarization_model_and_tokenizer()\n",
    "        \n",
    "    if not question_answer_model or not question_answer_tokenizer:\n",
    "#         print('GETTING QA OBJECTS')\n",
    "        question_answer_model, question_answer_tokenizer = model_settings.get_qa_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f755ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\n",
      "Importing modules...\n",
      "CLEARED previous modules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\transformers_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called AI_Project.AI_Model.run_preprocessing()...\n",
      "Loaded index from D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/doc_index.index\n",
      "Loaded sentence_to_index_mapping from D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/sentence_to_index_mapping.json\n",
      "Final length of the index: 831\n",
      "Called AI_Project.AI_Model.train_model()\n",
      "Initialized History_Record for project_directory:\n",
      "\t D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\n",
      "\n",
      "History record BUILDING RUN:\n",
      "\tproject_name: Default\n",
      "\tversion: None\n",
      "\texperiment_name: None\n",
      "\tmlflow_experiment_id: Default\n",
      "tracking_directory set to: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\\build\n",
      "Loading experiment_location in historical record...\n",
      "Generating a run in order to determine its guid name\n",
      "TRACKING - GENERATING RUN...\n",
      "\n",
      "  GENERATING RUN RECORD...\n",
      "Backing up code to the artifact directory.\n",
      "Forcing reload of config file...\n",
      "Running LMM Tests...\n",
      "Sim score is 0.5060945749282837 for: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience.\n",
      "Sim score is 0.3656858205795288 for: As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a warmer climate.\n",
      "Sim score is 0.3291891813278198 for: Impact of climate changeA child looks out over a dried up lake\n",
      "â€œClimate change is already affecting the health of millions of people all over the world, and more importantly, climate change will worsen throughout this century.\n",
      "Sim score is 0.27864325046539307 for: People are experiencing climate change in diverse ways\n",
      "Climate change can affect our health, ability to grow food, housing, safety and work.\n",
      "Sim score is 0.2719811797142029 for: Some of us are already more vulnerable to climate impacts, such as people living in small island nations and other developing countries.\n",
      "Sim score is 0.263683557510376 for: The consequences of climate change now include, among others, intense droughts, water scarcity, severe fires, rising sea levels, flooding, melting polar ice, catastrophic storms and declining biodiversity.\n",
      "\n",
      "There were 6 sentences found out of a possible 25 that were above the threshold of 0.25\n",
      "doc_ids ['e5e9975d-5826-4664-83a7-92115931b302', 'e5e9975d-5826-4664-83a7-92115931b302', 'e5e9975d-5826-4664-83a7-92115931b302', 'ae79310b-1c53-4784-b813-08537e483b7e', 'ae79310b-1c53-4784-b813-08537e483b7e', 'ae79310b-1c53-4784-b813-08537e483b7e']\n",
      "unique_doc_ids {'e5e9975d-5826-4664-83a7-92115931b302', 'ae79310b-1c53-4784-b813-08537e483b7e'}\n",
      "CSV file already exists at: D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/document_index.csv\n",
      "Loaded existing DataFrame:\n",
      "\n",
      "\n",
      "User question: How is global health affected by climate change?\n",
      "PROCESSING doc_id: e5e9975d-5826-4664-83a7-92115931b302 WorldHealthIssues_1.txt\n",
      "LOADING the QA model and tokenizer...\n",
      "Length of combined context: 172 max_length: 1024\n",
      "\n",
      "GENERATED SEQUENCE 1: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "LOADING the summarization model and tokenizer...\n",
      "\n",
      "SUMMARIZED SEQUENCE 1: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts, such as people living in small island nations and other developing countries. Climate change also affects people in the form of disease and other human-caused illnesses.\n",
      "\n",
      "\n",
      "GENERATED SEQUENCE 2: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "\n",
      "SUMMARIZED SEQUENCE 2: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts, such as people living in small island nations and other developing countries. More than 800,000 deaths and injuries could be caused by a change in how emissions are measured and how they are treated.\n",
      "\n",
      "\n",
      "GENERATED SEQUENCE 3: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "\n",
      "SUMMARIZED SEQUENCE 3: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts. The consequences of climate change now include intense droughts, water scarcity, severe fires, rising sea levels, flooding, melting polar ice, catastrophic storms and declining biodiversity.\n",
      "\n",
      "\n",
      "\n",
      "User question: How is global health affected by climate change?\n",
      "PROCESSING doc_id: e5e9975d-5826-4664-83a7-92115931b302 ClimateChange_1.txt\n",
      "Length of combined context: 172 max_length: 1024\n",
      "\n",
      "GENERATED SEQUENCE 1: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "\n",
      "SUMMARIZED SEQUENCE 1: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts, such as people living in small island nations and other developing countries. For climate change to be serious enough to prevent one or more major disasters, the consequences will have to be profound.\n",
      "\n",
      "\n",
      "GENERATED SEQUENCE 2: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "\n",
      "SUMMARIZED SEQUENCE 2: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts, such as people living in small island nations. Because climate change could affect food production, food has fewer calories than previously thought.\n",
      "\n",
      "\n",
      "GENERATED SEQUENCE 3: We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience. As we know from the pandemic, preparedness is key, and we are far from prepared for the health impacts of a wa\n",
      "\n",
      "SUMMARIZED SEQUENCE 3: Climate change is already affecting the health of millions of people all over the world, and more importantly, climate change will worsen throughout this century. People with sensitive or unhealthy conditions will find new opportunities for health on the rise. The most notable positive result that we now have from climate change is increased health outcomes.\n",
      "\n",
      "Processing 6 summaries.\n",
      "Generating a final answer and statistics\n",
      "The average summary comparison score is 0.9414992332458496 \n",
      "\tThe best summary comparison score is 0.9981199502944946 \n",
      "\tThe final summary comparison to the question is 0.7144916653633118\n",
      "\n",
      "\n",
      "User question: How is global health affected by climate change? \n",
      "FINAL ANSWER from all summaries: Climate change can affect our health, ability to grow food, housing, safety and work. Some of us are already more vulnerable to climate impacts, such as people living in small island nations. More than 800,000 deaths and injuries could be caused by a change in how emissions are measured and how they are treated.\n",
      "Archiving preprocessing commands...\n",
      "USING THE PRELOADED summarization model and tokenizer...\n"
     ]
    }
   ],
   "source": [
    "project = Project(project_name)\n",
    "preload_models_as_needed()\n",
    "    \n",
    "preprocessing_command = {\"number_of_qa_sentences_to_generate\": 3}\n",
    "# preprocessing_command = {\"check_for_new_docs\": True}\n",
    "\n",
    "# Set the command and train from the previous run\n",
    "project.model.run_preprocessing(preprocessing_command)\n",
    "project.model.train_model()\n",
    "set_models_as_needed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abe3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for running WINDOWS server on port 5001 using command: netstat -aon | findstr \":5001 \"\n",
      "project_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\n",
      "build_uri_directory: file:///D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/QA_Pipeline/QA_Pipeline_Testing/build\n",
      "Need the following:\n",
      "\t mlflow ui --backend-store-uri file:///D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/QA_Pipeline/QA_Pipeline_Testing/build\n",
      "Server started at file:///D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/QA_Pipeline/QA_Pipeline_Testing/build \n",
      "\tLog in at http://127.0.0.1:5001\n",
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "project_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\n",
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "Server started at D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\QA_Pipeline_Testing\\build :\n",
      "\tLog in at http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "project.start_server()\n",
    "project.start_ml_champ_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d43ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for running WINDOWS server on port 5001 using command: netstat -aon | findstr \":5001 \"\n",
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "\n",
      "Found running server on pid 25884 from\n",
      "\t   TCP    0.0.0.0:5000           0.0.0.0:0              LISTENING       25884\n",
      "Shutting down server on port 5000 and pid 25884\n",
      "Checking for running WINDOWS server on port 5002 using command: netstat -aon | findstr \":5002 \"\n"
     ]
    }
   ],
   "source": [
    "# project.stop_server(5001)      # Default is 5001 (MLflow server)\n",
    "# project.stop_server(5000)  # Default ML CHAMP server port\n",
    "# project.stop_server(5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f30d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e443e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd423f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef502e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers_env]",
   "language": "python",
   "name": "conda-env-transformers_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
