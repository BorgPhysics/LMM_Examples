{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397dec6e",
   "metadata": {},
   "source": [
    "## Question Explorer using ML-CHAMP\n",
    "\n",
    "Now that we have an initial working QA pipeline, we can begin to fine-tune the various components using ML-CHAMP to test and document various changes and settings while documenting the code that was generated, FAISS indexes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1824fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "from ml_champ import Project\n",
    "from ml_champ import Ensemble\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f5de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Importing modules...\n"
     ]
    }
   ],
   "source": [
    "project_name = 'Q_Explorer'\n",
    "project = Project(project_name)\n",
    "# print(dir(project))\n",
    "# print(dir(project.model))\n",
    "\n",
    "summary_model, summary_tokenizer = None, None\n",
    "question_answer_model, question_answer_tokenizer = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4421d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "\n",
    "    # from model_settings import get_summarization_model_and_tokenizer\n",
    "    if summary_model and summary_tokenizer:\n",
    "        if not model_settings.summarization_model and not model_settings.summarization_tokenizer:\n",
    "            model_settings.set_summarization_model_and_tokenizer(summary_model, summary_tokenizer)\n",
    "\n",
    "    # from model_settings import get_qa_model_and_tokenizer\n",
    "    if question_answer_model and question_answer_tokenizer:\n",
    "        if not model_settings.qa_model and not model_settings.qa_tokenizer:\n",
    "            model_settings.set_qa_model_and_tokenizer(question_answer_model, question_answer_tokenizer)\n",
    "    \n",
    "def set_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "    \n",
    "    if not summary_model or not summary_tokenizer:\n",
    "        summary_model, summary_tokenizer = model_settings.get_summarization_model_and_tokenizer()\n",
    "        \n",
    "    if not question_answer_model or not question_answer_tokenizer:\n",
    "        question_answer_model, question_answer_tokenizer = model_settings.get_qa_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f755ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Importing modules...\n",
      "CLEARED previous modules.\n",
      "SETTING the summarization model and tokenizer...\n",
      "SETTING the QA model and tokenizer...\n",
      "Called AI_Project.AI_Model.train_model()\n",
      "CSV file already exists at: D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/document_guid_lookup.csv\n",
      "Loaded existing DataFrame of size 12\n",
      "Loaded sentence_to_index_mapping from D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/sentence_to_index_mapping.json\n",
      "Initialized History_Record for project_directory:\n",
      "\t D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "\n",
      "History record BUILDING RUN:\n",
      "\tproject_name: Default\n",
      "\tversion: None\n",
      "\texperiment_name: None\n",
      "\tmlflow_experiment_id: Default\n",
      "tracking_directory set to: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build\n",
      "Loading experiment_location in historical record...\n",
      "Generating a run in order to determine its guid name\n",
      "TRACKING - GENERATING RUN...\n",
      "\n",
      "  GENERATING RUN RECORD...\n",
      "Backing up code to the artifact directory.\n",
      "Forcing reload of config file...\n",
      "No initial questions found, loaded stored questions.\n",
      "Processing questions.\n",
      "\t ['What are the main concerns with AI?']\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 0 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "No prompts found.  Updating similarity_threshold to 0.25\n",
      "\n",
      "There were 9 sentences found out of a possible 50 that were above the threshold of 0.25\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 00226ddc-431c-4943-8409-2ac0b7dac433 AI_4.txt \n",
      "\t\t Concerns, further future, and sentient artificial intelligence\n",
      "Technology can be misused.\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t As a General-Purpose Technology, AI will affect many areas of the\n",
      "commercial and military sectors.\n",
      "\n",
      "\t 80d78a9b-57d2-4060-9667-92e9378abaf3 AI_3.txt \n",
      "\t\t Privacy and data security also remain critical concerns, as AI applications deal with vast amounts of personal information.\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t This type of AI technology also could create critical privacy, security, confidentiality, and content concerns.\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t Although AI has clear benefits, it also brings many legal implications.\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t What will artificial intelligence do to industries and jobs?\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t The challenges they faced were tremendous.122\n",
      "Unfortunately, AI has the potential to be every bit as fraught with risk\n",
      "as these prior cases, perhaps more so given the speed of technological\n",
      "progress and the more complicated relationship between go\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t However, the reliance on AI as a decision-making mechanism has its risks, especially a financial risk to the user.\n",
      "\n",
      "\t 00226ddc-431c-4943-8409-2ac0b7dac433 AI_4.txt \n",
      "\t\t Current forms of AI have limits.\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: What are the main concerns with AI?\n",
      "\tProcessing 2 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ".. - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE:  AI has the potential to be every bit as fraught with risk as prior cases, perhaps more so given the speed of technological progress. Privacy and data security remain critical concerns, as AI applications deal with vast amounts of personal information. The real benefits of AI o\n",
      "AVERAGE SCORE: 0.8070699355342272 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "Generating overall statistics...\n",
      "\n",
      "HISTORICAL set_tag() method.\n",
      "\tself.run_id: b55de8d68ebe43b78cacb028482bdf0c\n",
      "\tself.run_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build\\Default\\b55de8d68ebe43b78cacb028482bdf0c\n",
      "Highest Scoring Methodology: Question & FAISS Vector\n",
      "Average Score: 0.8070699355342272\n",
      "\n",
      "\n",
      "\n",
      "Archiving preprocessing commands...\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1, 6):\n",
    "#     print(i)\n",
    "initial_question = None\n",
    "# initial_question = \"What are the main concerns with AI with respect to terrorism?\"\n",
    "initial_question = \"How is global health affected by climate change?\"\n",
    "    \n",
    "project = Project(project_name)\n",
    "preload_models_as_needed()\n",
    "    \n",
    "preprocessing_command = {}\n",
    "\n",
    "if initial_question:\n",
    "#     preprocessing_command = {\"similarity_threshold\": 0.2, \n",
    "#                              \"number_of_qa_sentences_to_generate\": 2}\n",
    "    preprocessing_command = {'initial_question': initial_question, \n",
    "                             \"similarity_threshold\": 0.2, \n",
    "                             \"number_of_qa_sentences_to_generate\": 2}\n",
    "#     project.model.run_preprocessing(preprocessing_command)    \n",
    "\n",
    "# preprocessing_command = {\"similarity_threshold\": 0.4}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "# preprocessing_command = {\"number_of_qa_sentences_to_generate\": 1}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "# preprocessing_command = {\"check_for_new_docs\": True}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "\n",
    "# Set the command and train from the previous run\n",
    "project.model.train_model()\n",
    "set_models_as_needed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abe3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "project_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "Server started at D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build :\n",
      "\tLog in at http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "# server_directory='/D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/QA_Pipeline/QA_Pipeline_Testing/', port=5001\n",
    "# project.start_server()\n",
    "project.start_ml_champ_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d43ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.stop_server(5001)      # Default is 5001 (MLflow server)\n",
    "# project.stop_server(5000)  # Default ML CHAMP server port\n",
    "# project.stop_server(5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f30d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e443e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd423f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef502e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers_env]",
   "language": "python",
   "name": "conda-env-transformers_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
