{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397dec6e",
   "metadata": {},
   "source": [
    "## Question Explorer using ML-CHAMP\n",
    "\n",
    "Now that we have an initial working QA pipeline, we can begin to fine-tune the various components using ML-CHAMP to test and document various changes and settings while documenting the code that was generated, FAISS indexes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1824fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "from ml_champ import Project\n",
    "from ml_champ import Ensemble\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f5de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Importing modules...\n"
     ]
    }
   ],
   "source": [
    "project_name = 'Q_Explorer'\n",
    "project = Project(project_name)\n",
    "# print(dir(project))\n",
    "# print(dir(project.model))\n",
    "\n",
    "summary_model, summary_tokenizer = None, None\n",
    "question_answer_model, question_answer_tokenizer = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4421d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "\n",
    "    # from model_settings import get_summarization_model_and_tokenizer\n",
    "    if summary_model and summary_tokenizer:\n",
    "        if not model_settings.summarization_model and not model_settings.summarization_tokenizer:\n",
    "            model_settings.set_summarization_model_and_tokenizer(summary_model, summary_tokenizer)\n",
    "\n",
    "    # from model_settings import get_qa_model_and_tokenizer\n",
    "    if question_answer_model and question_answer_tokenizer:\n",
    "        if not model_settings.qa_model and not model_settings.qa_tokenizer:\n",
    "            model_settings.set_qa_model_and_tokenizer(question_answer_model, question_answer_tokenizer)\n",
    "    \n",
    "def set_models_as_needed():\n",
    "    global project\n",
    "    global summary_model\n",
    "    global summary_tokenizer\n",
    "    global question_answer_model\n",
    "    global question_answer_tokenizer\n",
    "    \n",
    "    ai_project = project.model.get_ai_project()\n",
    "    from ai_project.qa_pipeline.models import model_settings\n",
    "    \n",
    "    if not summary_model or not summary_tokenizer:\n",
    "        summary_model, summary_tokenizer = model_settings.get_summarization_model_and_tokenizer()\n",
    "        \n",
    "    if not question_answer_model or not question_answer_tokenizer:\n",
    "        question_answer_model, question_answer_tokenizer = model_settings.get_qa_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f755ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tworking_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Importing modules...\n",
      "CLEARED previous modules.\n",
      "SETTING the summarization model and tokenizer...\n",
      "SETTING the QA model and tokenizer...\n",
      "Called AI_Project.AI_Model.train_model()\n",
      "CSV file already exists at: D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/document_guid_lookup.csv\n",
      "Loaded existing DataFrame of size 12\n",
      "Loaded sentence_to_index_mapping from D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/data/sentence_to_index_mapping.json\n",
      "Initialized History_Record for project_directory:\n",
      "\t D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "\n",
      "History record BUILDING RUN:\n",
      "\tproject_name: Default\n",
      "\tversion: None\n",
      "\texperiment_name: None\n",
      "\tmlflow_experiment_id: Default\n",
      "tracking_directory set to: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build\n",
      "Loading experiment_location in historical record...\n",
      "Generating a run in order to determine its guid name\n",
      "TRACKING - GENERATING RUN...\n",
      "\n",
      "  GENERATING RUN RECORD...\n",
      "Backing up code to the artifact directory.\n",
      "Forcing reload of config file...\n",
      "No initial questions found, loaded stored questions.\n",
      "Processing questions.\n",
      "\t ['Could you provide a comprehensive overview of the impact of climate change on global health, considering various aspects and potential implications?', 'How is global health affected by climate change?', 'How will AI help us in the future?', 'What are the main concerns with \n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 1 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 783fb29b-29b0-4622-9a63-e19ebe0a1f68 WorldHealthIssues_1.txt \n",
      "\t\t We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience.\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: Could you provide a comprehensive overview of the impact of climate change on global health, considering various aspects and potential implications?\n",
      "\tProcessing 1 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ". - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: The World Health Organization has announced an ambitious plan to tackle the global warming challenge by 2050. Even in developed countries, the proportion of individuals and small populations experiencing health problems from climate change or the impacts of climate change have \n",
      "AVERAGE SCORE: 0.8198295022019897 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 1 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 783fb29b-29b0-4622-9a63-e19ebe0a1f68 WorldHealthIssues_1.txt \n",
      "\t\t We are now at a point where climate change is clearly with us, and much more attention needs to be put on minimizing the impacts on global health through adaptation or enhancing resilience.\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: How is global health affected by climate change?\n",
      "\tProcessing 1 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ". - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: Global food security and food security are two of the world's unique challenges. Achieving these long-term sustainability challenges, through adaptation and adaptation to climate change, will require us to adapt our food systems.\n",
      "AVERAGE SCORE: 0.48352454903881964 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 1 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t What will artificial intelligence do to industries and jobs?\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: How will AI help us in the future?\n",
      "\tProcessing 1 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ". - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: Summarize: New Career and Education is a collaboration of 16 start-ups between 14 companies, as well as 18 universities, universities and research institutes. Our aim is to get deep-learning and artificial intelligence into our lives that will help our industry thrive.\n",
      "AVERAGE SCORE: 0.45639653362242644 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 0 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "No prompts found.  Updating similarity_threshold to 0.25\n",
      "\n",
      "There were 9 sentences found out of a possible 50 that were above the threshold of 0.25\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 00226ddc-431c-4943-8409-2ac0b7dac433 AI_4.txt \n",
      "\t\t Concerns, further future, and sentient artificial intelligence\n",
      "Technology can be misused.\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t As a General-Purpose Technology, AI will affect many areas of the\n",
      "commercial and military sectors.\n",
      "\n",
      "\t 80d78a9b-57d2-4060-9667-92e9378abaf3 AI_3.txt \n",
      "\t\t Privacy and data security also remain critical concerns, as AI applications deal with vast amounts of personal information.\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t This type of AI technology also could create critical privacy, security, confidentiality, and content concerns.\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t Although AI has clear benefits, it also brings many legal implications.\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t What will artificial intelligence do to industries and jobs?\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t The challenges they faced were tremendous.122\n",
      "Unfortunately, AI has the potential to be every bit as fraught with risk\n",
      "as these prior cases, perhaps more so given the speed of technological\n",
      "progress and the more complicated relationship between go\n",
      "\n",
      "\t 0a2a5371-9efa-4690-b0cb-f178af34228b AI_6.txt \n",
      "\t\t However, the reliance on AI as a decision-making mechanism has its risks, especially a financial risk to the user.\n",
      "\n",
      "\t 00226ddc-431c-4943-8409-2ac0b7dac433 AI_4.txt \n",
      "\t\t Current forms of AI have limits.\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: What are the main concerns with AI?\n",
      "\tProcessing 2 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ".. - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: AI has the potential to be every bit as fraught with risk as previous technologies. Privacy and data security also remain critical concerns, as AI applications deal with vast amounts of personal information. As a General Purpose Technology, AI will affect industries and jobs.\n",
      "AVERAGE SCORE: 0.6506074276177162 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 3 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t What will artificial intelligence do to industries and jobs?\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t Will AI transform industries?\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t AI applications can\n",
      "therefore act as an “innovation supercharger.”\n",
      "Automation and Unemployment\n",
      "The 2016 White House Report on Artificial Intelligence, Automation,\n",
      "and the Economy found that increasing automation will threaten\n",
      "millions of jobs77 an\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: How will AI affect skilled labor?\n",
      "\tProcessing 1 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: The 2016 White House Report on Artificial Intelligence, Automation, and the Economy found that increasing automation will threaten millions of jobs. Machines will likely continue to serve as the backbone of US public services and make most of the US labor force obsolete.\n",
      "AVERAGE SCORE: 0.7220642185130025 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "NOTE: All methodology types are used as an input context to the final LMM model.\n",
      "\n",
      "\n",
      "There were 0 sentences found out of a possible 50 that were above the threshold of 0.5\n",
      "No prompts found.  Updating similarity_threshold to 0.25\n",
      "\n",
      "There were 8 sentences found out of a possible 50 that were above the threshold of 0.25\n",
      "\n",
      "\tThe doc ID, doc name and sentences used for this summary were:\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t What will artificial intelligence do to industries and jobs?\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t By 1960, there were fewer than 3 million.83 If artificial intelligence significantly and permanently reduces demand for human unskilled\n",
      "labor, and if significant portions of the unskilled labor workforce struggle\n",
      "38 Artificial Intelligence and Nat\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t AI applications can\n",
      "therefore act as an “innovation supercharger.”\n",
      "Automation and Unemployment\n",
      "The 2016 White House Report on Artificial Intelligence, Automation,\n",
      "and the Economy found that increasing automation will threaten\n",
      "millions of jobs77 an\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t If AI does lead to permanent worker displacement, technologically\n",
      "advanced countries may face the “Resource Curse” problem, whereby\n",
      "the owners of productive capital are highly concentrated, and economics and politics become unstable.\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t ■ Former U.S. Treasury Secretary Larry Summers has predicted\n",
      "that advances in AI and related technologies will lead to a dramatic decline in demand for labor such that the United States\n",
      "“may have a third of men between the ages of 25 and 54 not\n",
      "wo\n",
      "\n",
      "\t 61f06291-5385-4dfb-acda-88f74e955c15 AI_2.txt \n",
      "\t\t In particular, we analyze\n",
      "how future progress in AI technology will affect the speed of technological\n",
      "innovation, and the how increases in automation will affect employment.\n",
      "\n",
      "\t 1733c782-c96f-4594-91bc-e331af52112d AI_5.txt \n",
      "\t\t Will AI transform industries?\n",
      "\n",
      "\t 00226ddc-431c-4943-8409-2ac0b7dac433 AI_4.txt \n",
      "\t\t It will also replace many human jobs.\n",
      "\n",
      "\n",
      "METHODOLOGY: Question & FAISS Vector\n",
      "This methodology submits the user question to the FAISS index to find all of the related sentences within the assigned parameter ranges.  It then uses the question and FAISS sentences as context for the final LMM.\n",
      "ORIGINAL QUESTION: How will AI affect unskilled labor?\n",
      "\tProcessing 2 text chunk(s).\n",
      "\tProcessing tokenized chunk(s).\n",
      ".. - COMPLETED...\n",
      "\n",
      "SUMMARIZED RESPONSE: White House report: Increasing automation will threaten millions of jobs. One million Americans will lose their jobs by 2050, report says. U.S. economy already presents increasing economic challenges, author says.\n",
      "AVERAGE SCORE: 0.3018593204859679 \n",
      "END OF Question & FAISS Vector METHODOLOGY\n",
      "\n",
      "\n",
      "Generating question statistics...\n",
      "Generating overall statistics...\n",
      "\n",
      "HISTORICAL set_tag() method.\n",
      "\tself.run_id: 8d319a8f6d8a4deeb9a946ddd043fb46\n",
      "\tself.run_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build\\Default\\8d319a8f6d8a4deeb9a946ddd043fb46\n",
      "Highest Scoring Methodology: Question & FAISS Vector\n",
      "Average Score: 0.5723802585799871\n",
      "\n",
      "\n",
      "\n",
      "Archiving preprocessing commands...\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1, 6):\n",
    "#     print(i)\n",
    "initial_question = None\n",
    "# initial_question = \"What are the main concerns with AI with respect to terrorism?\"\n",
    "initial_question = \"How is global health affected by climate change?\"\n",
    "    \n",
    "project = Project(project_name)\n",
    "preload_models_as_needed()\n",
    "    \n",
    "preprocessing_command = {}\n",
    "\n",
    "if initial_question:\n",
    "#     preprocessing_command = {\"similarity_threshold\": 0.2, \n",
    "#                              \"number_of_qa_sentences_to_generate\": 2}\n",
    "    preprocessing_command = {'initial_question': initial_question, \n",
    "                             \"similarity_threshold\": 0.2, \n",
    "                             \"number_of_qa_sentences_to_generate\": 2}\n",
    "#     project.model.run_preprocessing(preprocessing_command)    \n",
    "\n",
    "# preprocessing_command = {\"similarity_threshold\": 0.4}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "# preprocessing_command = {\"number_of_qa_sentences_to_generate\": 1}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "# preprocessing_command = {\"check_for_new_docs\": True}\n",
    "# project.model.run_preprocessing(preprocessing_command)\n",
    "\n",
    "# Set the command and train from the previous run\n",
    "project.model.train_model()\n",
    "set_models_as_needed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abe3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "project_directory: D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\n",
      "Checking for running WINDOWS server on port 5000 using command: netstat -aon | findstr \":5000 \"\n",
      "Server started at D:\\JupyterPrograms\\0-CHAT_GPT\\EXPERIMENTS\\ML_CHAMP\\QA_Pipeline\\Q_Explorer\\build :\n",
      "\tLog in at http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "# server_directory='/D:/JupyterPrograms/0-CHAT_GPT/EXPERIMENTS/ML_CHAMP/QA_Pipeline/QA_Pipeline_Testing/', port=5001\n",
    "# project.start_server()\n",
    "project.start_ml_champ_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d43ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.stop_server(5001)      # Default is 5001 (MLflow server)\n",
    "# project.stop_server(5000)  # Default ML CHAMP server port\n",
    "# project.stop_server(5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f30d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e443e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd423f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef502e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers_env]",
   "language": "python",
   "name": "conda-env-transformers_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
